{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9253aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from data_loader import HotpotQALoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d37ec",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loader\n",
    "loader = HotpotQALoader(subset_size=100, random_seed=42)\n",
    "\n",
    "# Load full dataset\n",
    "loader.load_dataset(split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c7792",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few examples\n",
    "examples = [loader.dataset[i] for i in range(5)]\n",
    "\n",
    "print(\"Example question:\")\n",
    "print(f\"Question: {examples[0]['question']}\")\n",
    "print(f\"Answer: {examples[0]['answer']}\")\n",
    "print(f\"Type: {examples[0]['type']}\")\n",
    "print(f\"\\nSupporting facts: {examples[0]['supporting_facts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze answer lengths\n",
    "answer_lengths = [len(ex['answer'].split()) for ex in loader.dataset]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(answer_lengths, bins=50, edgecolor='black')\n",
    "plt.xlabel('Answer Length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Answer Lengths in HotpotQA')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean answer length: {sum(answer_lengths)/len(answer_lengths):.2f} words\")\n",
    "print(f\"Median answer length: {sorted(answer_lengths)[len(answer_lengths)//2]} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question types\n",
    "question_types = [ex['type'] for ex in loader.dataset]\n",
    "type_counts = pd.Series(question_types).value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "type_counts.plot(kind='bar')\n",
    "plt.xlabel('Question Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Question Types')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2eea9b",
   "metadata": {},
   "source": [
    "## 3. Create and Analyze Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7301f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset\n",
    "subset = loader.create_subset(strategy='random')\n",
    "\n",
    "print(f\"Created subset with {len(subset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze subset characteristics\n",
    "subset_df = pd.DataFrame([\n",
    "    {\n",
    "        'id': ex['id'],\n",
    "        'question_length': len(ex['question'].split()),\n",
    "        'answer_length': len(ex['answer'].split()),\n",
    "        'type': ex['type'],\n",
    "        'n_supporting_facts': len(ex['supporting_facts']['title'])\n",
    "    }\n",
    "    for ex in subset\n",
    "])\n",
    "\n",
    "print(subset_df.describe())\n",
    "print(f\"\\nQuestion types in subset:\")\n",
    "print(subset_df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1234869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize subset statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Question lengths\n",
    "axes[0].hist(subset_df['question_length'], bins=20, edgecolor='black')\n",
    "axes[0].set_xlabel('Question Length (words)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Subset: Question Lengths')\n",
    "\n",
    "# Supporting facts\n",
    "axes[1].hist(subset_df['n_supporting_facts'], bins=10, edgecolor='black')\n",
    "axes[1].set_xlabel('Number of Supporting Facts')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Subset: Supporting Facts per Question')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b64fc",
   "metadata": {},
   "source": [
    "## 4. Prepare Corpus for Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare corpus\n",
    "corpus = loader.prepare_corpus()\n",
    "\n",
    "print(f\"Corpus size: {len(corpus)} passages\")\n",
    "\n",
    "# Analyze corpus\n",
    "passage_lengths = [len(p['text'].split()) for p in corpus]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(passage_lengths, bins=50, edgecolor='black')\n",
    "plt.xlabel('Passage Length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Passage Lengths in Corpus')\n",
    "plt.axvline(sum(passage_lengths)/len(passage_lengths), color='red', linestyle='--', label='Mean')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean passage length: {sum(passage_lengths)/len(passage_lengths):.2f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06171692",
   "metadata": {},
   "source": [
    "## 5. Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample questions with answers\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "samples = random.sample(subset, 5)\n",
    "\n",
    "for i, example in enumerate(samples, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Example {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Question: {example['question']}\")\n",
    "    print(f\"Answer: {example['answer']}\")\n",
    "    print(f\"Type: {example['type']}\")\n",
    "    print(f\"Supporting facts: {example['supporting_facts']['title'][:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4680a3",
   "metadata": {},
   "source": [
    "## 6. Save Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save subset for experiments\n",
    "loader.save_subset('../data/hotpotqa_subset.json')\n",
    "\n",
    "# Save corpus\n",
    "import json\n",
    "with open('../data/corpus.json', 'w') as f:\n",
    "    json.dump(corpus, f, indent=2)\n",
    "\n",
    "print(\"Dataset subset and corpus saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18012d9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Loaded HotpotQA validation set\n",
    "- Created random subset of 100 examples\n",
    "- Prepared corpus with passages for retrieval\n",
    "- Analyzed dataset characteristics\n",
    "- Saved data for experiments"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
